import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor
import onnxmltools
from onnxmltools.convert.common.data_types import FloatTensorType
import onnxruntime as rt

# ===========================
# 1Ô∏è‚É£ T·∫†O D·ªÆ LI·ªÜU GI·∫¢ L·∫¨P
# ===========================

np.random.seed(42)
n_samples = 1000

# C√°c feature ƒë·∫ßu v√†o
data = pd.DataFrame({
    "totalBookings_month": np.random.randint(150, 300, n_samples),  # Keep only monthly bookings
    "avgtempC": np.random.uniform(20, 35, n_samples),
    "dailyChanceOfRain": np.random.randint(0, 100, n_samples),
    "isHoliday": np.random.randint(0, 2, n_samples)
})

# Bi·∫øn m·ª•c ti√™u: s·ªë l∆∞·ª£t ƒë·∫∑t s√¢n ng√†y mai
totalBookings_tomorrow = []
for i in range(len(data)):
    tb_month = data["totalBookings_month"].iloc[i]
    temp = data["avgtempC"].iloc[i]
    rain = data["dailyChanceOfRain"].iloc[i]
    holiday = data["isHoliday"].iloc[i]
    
    val = (
        (tb_month / 30) * 0.8 +                    # tr·ªçng s·ªë c·ªßa trung b√¨nh th√°ng
        (35 - temp) * 0.3 +                        # tr·ªçng s·ªë c·ªßa nhi·ªát ƒë·ªô
        (rain / 100) * (-2.0) +                    # tr·ªçng s·ªë c·ªßa m∆∞a
        holiday * 2 +                              # tr·ªçng s·ªë ng√†y l·ªÖ
        np.random.normal(0, 0.3)                   # nhi·ªÖu ng·∫´u nhi√™n
    )
    totalBookings_tomorrow.append(val)

data["totalBookings_tomorrow"] = totalBookings_tomorrow

# ===========================
# 2Ô∏è‚É£ CHU·∫®N B·ªä D·ªÆ LI·ªÜU
# ===========================

X = data[["totalBookings_month", "avgtempC", "dailyChanceOfRain", "isHoliday"]]
# ƒê·ªïi t√™n c√°c c·ªôt th√†nh f0, f1, f2, f3
X.columns = [f'f{i}' for i in range(X.shape[1])]
y = data["totalBookings_tomorrow"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ===========================
# 3Ô∏è‚É£ HU·∫§N LUY·ªÜN M√î H√åNH XGBOOST
# ===========================

model = XGBRegressor(
    n_estimators=120,
    max_depth=4,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"‚úÖ Hu·∫•n luy·ªán th√†nh c√¥ng. RMSE = {rmse:.3f}")

# ===========================
# 4Ô∏è‚É£ XU·∫§T M√î H√åNH SANG ONNX
# ===========================

# ƒê·ªãnh nghƒ©a input shape v√† t√™n
input_type = [('float_input', FloatTensorType([None, X.shape[1]]))]

# Chuy·ªÉn ƒë·ªïi sang ONNX v·ªõi target opset m·ªõi nh·∫•t
onnx_model = onnxmltools.convert_xgboost(model, 
                                        initial_types=input_type,
                                        target_opset=13)

# L∆∞u m√¥ h√¨nh
with open("field_booking_xgb.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

print("‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh ONNX: field_booking_xgb.onnx")

# ===========================
# 5Ô∏è‚É£ KI·ªÇM TRA L·∫†I M√î H√åNH B·∫∞NG ONNXRUNTIME
# ===========================

sess = rt.InferenceSession("field_booking_xgb.onnx", providers=['CPUExecutionProvider'])
input_name = sess.get_inputs()[0].name

sample = np.array([[162.0, 28.0, 50.0, 0.0]], dtype=np.float32)
pred = sess.run(None, {input_name: sample})[0]

print("üîç D·ª± ƒëo√°n th·ª≠ v·ªõi input [2, 162, 28, 50, 0] ‚Üí", pred)
